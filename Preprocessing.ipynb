{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialect Classification Data Preparation and Cleaning\n",
    "\n",
    "This notebook demonstrates the process of extracting data from an SQLite database, cleaning the text data, balancing the dataset, and saving the final processed data to a CSV file. This is essential for training a model for dialect classification.\n",
    "\n",
    "## Step 1: Import Libraries\n",
    "\n",
    "First, we import the necessary libraries for data manipulation and text processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?<br>\n",
    "sqlite3: To connect to the SQLite database and execute SQL queries.<br>\n",
    "pandas: For data manipulation and analysis.<br>\n",
    "### Benefit<br>\n",
    "These libraries provide the essential tools needed to handle, process, and clean the data efficiently.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Data from SQLite Database\n",
    "We connect to the SQLite database and fetch the data from two tables: id_text and id_dialect. The data is then merged into a single DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why? <br>\n",
    "To retrieve the data stored in the SQLite database and combine it into a single DataFrame that includes both text and dialect information.<br>\n",
    "## Benefit<br>\n",
    "This step ensures that we have a unified dataset with all necessary information in one place, making it easier to process and analyze<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = sqlite3.connect('Data/dialects_database.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch table names (for information purposes)\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "table_names = [table[0] for table in tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all rows from the id_text and id_dialect tables\n",
    "cursor.execute('SELECT * FROM id_text')\n",
    "id_text = cursor.fetchall()\n",
    "cursor.execute('SELECT * FROM id_dialect')\n",
    "id_dialect = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009754958479151232</td>\n",
       "      <td>@toha_Altomy @gy_yah قليلين ادب ومنافقين. لو ا...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009794751548313600</td>\n",
       "      <td>@AlmFaisal 😂😂 الليبيين متقلبين!!!\\nبس بالنسبة ...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1019989115490787200</td>\n",
       "      <td>@smsm071990 @ALMOGRBE كل 20 تانيه شاب ليبي بير...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1035479791758135168</td>\n",
       "      <td>@AboryPro @lyranoo85 رانيا عقليتك متخلفة. اولا...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035481122921164800</td>\n",
       "      <td>@lyranoo85 شكلك متعقدة علشان الراجل لي تحبيه ا...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1009754958479151232  @toha_Altomy @gy_yah قليلين ادب ومنافقين. لو ا...   \n",
       "1  1009794751548313600  @AlmFaisal 😂😂 الليبيين متقلبين!!!\\nبس بالنسبة ...   \n",
       "2  1019989115490787200  @smsm071990 @ALMOGRBE كل 20 تانيه شاب ليبي بير...   \n",
       "3  1035479791758135168  @AboryPro @lyranoo85 رانيا عقليتك متخلفة. اولا...   \n",
       "4  1035481122921164800  @lyranoo85 شكلك متعقدة علشان الراجل لي تحبيه ا...   \n",
       "\n",
       "  dialect  \n",
       "0      LY  \n",
       "1      LY  \n",
       "2      LY  \n",
       "3      LY  \n",
       "4      LY  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrames from the fetched data\n",
    "id_text_df = pd.DataFrame(id_text, columns=['id', 'text'])\n",
    "id_dialect_df = pd.DataFrame(id_dialect, columns=['id', 'dialect'])\n",
    "\n",
    "# Merge the two DataFrames on the 'id' column\n",
    "merged_df = pd.merge(id_text_df, id_dialect_df, on='id')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Save the Merged DataFrame\n",
    "The merged DataFrame is saved to a CSV file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged DataFrame to a CSV file\n",
    "merged_df.to_csv('Data/merged_dataframe.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Cleaning\n",
    "We remove the 'id' column and clean the text data by removing diacritics, non-Arabic characters, extra spaces, and stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why? <br>\n",
    "Remove 'id' column: The 'id' column is not needed for text analysis and classification.<br>\n",
    "Text Cleaning: To standardize the text by removing unnecessary characters and stopwords which can improve the performance of the machine learning model.<br>\n",
    "## Benefit<br>\n",
    "This step ensures that the text data is in a clean and uniform format, which is crucial for accurate text classification.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LY', 'MA', 'EG', 'LB', 'SD'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dialect'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialect\n",
       "EG    57636\n",
       "LY    36499\n",
       "LB    27617\n",
       "SD    14434\n",
       "MA    11539\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_counts = df['dialect'].value_counts()\n",
    "dialect_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147725 entries, 0 to 147724\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   text     147725 non-null  object\n",
      " 1   dialect  147725 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['dialect'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply clean text function to train data\n",
    "X_train = X_train.apply(clean_text)\n",
    "#apply clean text function to test data\n",
    "X_test = X_test.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataframe\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "X_train = X_train.dropna(subset=['text'])\n",
    "X_test = X_test.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned dataframes\n",
    "X_train.to_csv('Data/X_train.csv', index=False, encoding='utf-8-sig')\n",
    "X_test.to_csv('Data/X_test.csv', index=False, encoding='utf-8-sig')\n",
    "y_train.to_csv('Data/y_train.csv', index=False, encoding='utf-8-sig')\n",
    "y_test.to_csv('Data/y_test.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Upsample Data to Balance Classes\n",
    "We perform upsampling on the minority classes to balance the dataset.<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefit\n",
    "Balancing the dataset helps in training a more robust and fair model, reducing the bias towards majority classes and improving overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_X_train = pd.read_csv('Data/X_train.csv')\n",
    "# df_Y_train = pd.read_csv('Data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate features and labels\n",
    "df = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57485</th>\n",
       "      <td>الدنيا دي الحلو والوحش</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61118</th>\n",
       "      <td>انا بقيت اعمل كده علي فكره ليه اوجع ايدي تقليب...</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48452</th>\n",
       "      <td>البوست بتاع خافيير سولانا طلع انه هاكر تركي اخ...</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95030</th>\n",
       "      <td>احلي دي ايه افريقياياوداد</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96136</th>\n",
       "      <td>حبيبي قدها كبير والله</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text dialect\n",
       "57485                             الدنيا دي الحلو والوحش      EG\n",
       "61118  انا بقيت اعمل كده علي فكره ليه اوجع ايدي تقليب...      EG\n",
       "48452  البوست بتاع خافيير سولانا طلع انه هاكر تركي اخ...      EG\n",
       "95030                          احلي دي ايه افريقياياوداد      EG\n",
       "96136                              حبيبي قدها كبير والله      EG"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialect\n",
       "EG    46152\n",
       "LY    29231\n",
       "LB    22039\n",
       "SD    11502\n",
       "MA     9256\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chcek data balance\n",
    "df.dialect.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsanpling data to make it balanced\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_classes = df[df['dialect'].isin(['EG', 'LY', 'LB'])]\n",
    "minority_classes = df[~df['dialect'].isin(['EG', 'LY', 'LB'])]  \n",
    "\n",
    "# Upsample minority class to match majority class size\n",
    "minority_upsampled = resample(minority_classes, \n",
    "                              replace=True,     # sample with replacement\n",
    "                              n_samples=int(len(majority_classes)*0.5),    \n",
    "                              random_state=42) # reproducible results\n",
    "\n",
    "# Combine minority_upsampled with majority_classes\n",
    "balanced_df = pd.concat([minority_upsampled, majority_classes])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialect\n",
      "EG    46152\n",
      "LY    29231\n",
      "SD    26854\n",
      "LB    22039\n",
      "MA    21857\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(balanced_df['dialect'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = balanced_df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save the Balanced DataFrame\n",
    "Finally, we save the balanced DataFrame to a CSV file for use in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save balanced dataframe\n",
    "balanced_df.to_csv('Data/Train_data.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save test data\n",
    "Test_data = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE TEST DATA\n",
    "Test_data.to_csv('Data/Test_data.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
