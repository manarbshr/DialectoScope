{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialect Classification Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will train and evaluate different machine learning models for dialect classification using a balanced dataset. We will also compare the performance of Logistic Regression, Decision Tree, and Naive Bayes models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "First, we import the necessary libraries for data manipulation and model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why? <br>\n",
    "pandas: For data manipulation and analysis.<br>\n",
    "numpy: For numerical operations.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Clean Data\n",
    "Load the balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>انا البلد ده مافيهاش حاجه عدل تقريبا عمر ماتقل...</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قروش المرجع اكتر قروشك</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لذلك خسنا كمغاربه نسكتوا شويه حتي نشوفوا نهايه...</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>حسني مبارك اتنحي لقا ناس بتموت المصريين ولانه ...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>العينبالعين جلست ضيوفك مازمه بيناتهن اكتر الاز...</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text dialect\n",
       "0  انا البلد ده مافيهاش حاجه عدل تقريبا عمر ماتقل...      EG\n",
       "1                             قروش المرجع اكتر قروشك      SD\n",
       "2  لذلك خسنا كمغاربه نسكتوا شويه حتي نشوفوا نهايه...      MA\n",
       "3  حسني مبارك اتنحي لقا ناس بتموت المصريين ولانه ...      SD\n",
       "4  العينبالعين جلست ضيوفك مازمه بيناتهن اكتر الاز...      LB"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Extraction\n",
    "We use the TfidfVectorizer to convert the text data into numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why? <br>\n",
    "TfidfVectorizer: To convert the text data into numerical features that can be used by machine learning models.<br>\n",
    "## Benefit<br>\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) helps in transforming textual data into meaningful numerical vectors, capturing the importance of words in the context of the documents<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping null values\n",
    "df_train = df_train.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data into TF-IDF features\n",
    "X = vectorizer.fit_transform(df_train['text'])\n",
    "y = df_train['dialect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train-Test Split\n",
    "We split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why? <br>\n",
    "Train-Test Split: To evaluate the performance of the model on unseen data.<br>\n",
    "## Benefit <br>\n",
    "This helps in assessing the generalizability of the model by testing it on a separate dataset that was not used during training.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Data/Test_data.csv')\n",
    "df_test = df_test.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(df_train[\"text\"])\n",
    "y_train = np.array(df_train[\"dialect\"])\n",
    "X_test = vectorizer.transform(df_test[\"text\"])\n",
    "y_test = np.array(df_test[\"dialect\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Logistic Regression Model\n",
    "We train a Logistic Regression model with a specified maximum number of iterations and solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression: A simple and effective linear model for classification tasks.<br>\n",
    "## Benefit <br>\n",
    "Logistic Regression provides a baseline performance for the dialect classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=50, solver='newton-cg', C=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we already did a grid search to find the best hyperparameters for the model.\n",
    "those are the outputs of uing different values for C and solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating its accuracy, classification report, confusion matrix, and macro F1 score helps in understanding the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9798625090724841\n",
      "Test accuracy: 0.8208045509955303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.84      0.90      0.87     11480\n",
      "          LB       0.87      0.82      0.84      5578\n",
      "          LY       0.80      0.81      0.81      7265\n",
      "          MA       0.79      0.69      0.74      2283\n",
      "          SD       0.72      0.64      0.68      2926\n",
      "\n",
      "    accuracy                           0.82     29532\n",
      "   macro avg       0.80      0.77      0.79     29532\n",
      "weighted avg       0.82      0.82      0.82     29532\n",
      "\n",
      "[[10351   202   487   115   325]\n",
      " [  412  4582   365    95   124]\n",
      " [  761   282  5856   147   219]\n",
      " [  290    86   266  1570    71]\n",
      " [  554   127   307    57  1881]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Train accuracy: {model.score(X_train, y_train)}')\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.983443572573025\n",
      "Test accuracy: 0.8199241500744955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.84      0.90      0.87     11480\n",
      "          LB       0.87      0.82      0.84      5578\n",
      "          LY       0.80      0.81      0.80      7265\n",
      "          MA       0.79      0.69      0.74      2283\n",
      "          SD       0.72      0.64      0.67      2926\n",
      "\n",
      "    accuracy                           0.82     29532\n",
      "   macro avg       0.80      0.77      0.79     29532\n",
      "weighted avg       0.82      0.82      0.82     29532\n",
      "\n",
      "[[10339   205   498   115   323]\n",
      " [  410  4593   361    93   121]\n",
      " [  761   284  5849   146   225]\n",
      " [  292    85   266  1569    71]\n",
      " [  557   132   312    61  1864]]\n"
     ]
    }
   ],
   "source": [
    "#C= 5\n",
    "print(f'Train accuracy: {model.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9905372279966586\n",
      "Test accuracy: 0.8174183936069348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.84      0.90      0.87     11480\n",
      "          LB       0.86      0.82      0.84      5578\n",
      "          LY       0.80      0.80      0.80      7265\n",
      "          MA       0.79      0.68      0.73      2283\n",
      "          SD       0.71      0.63      0.67      2926\n",
      "\n",
      "    accuracy                           0.82     29532\n",
      "   macro avg       0.80      0.77      0.78     29532\n",
      "weighted avg       0.82      0.82      0.82     29532\n",
      "\n",
      "[[10305   225   500   123   327]\n",
      " [  417  4582   371    90   118]\n",
      " [  765   288  5847   140   225]\n",
      " [  283    95   269  1563    73]\n",
      " [  568   135   317    63  1843]]\n"
     ]
    }
   ],
   "source": [
    "#C= 10\n",
    "print(f'Train accuracy: {model.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9390329074401216\n",
      "Test accuracy: 0.8159284843559529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.83      0.90      0.86     11480\n",
      "          LB       0.88      0.80      0.84      5578\n",
      "          LY       0.80      0.80      0.80      7265\n",
      "          MA       0.79      0.69      0.73      2283\n",
      "          SD       0.71      0.65      0.68      2926\n",
      "\n",
      "    accuracy                           0.82     29532\n",
      "   macro avg       0.80      0.77      0.78     29532\n",
      "weighted avg       0.82      0.82      0.81     29532\n",
      "\n",
      "[[10373   171   488   113   335]\n",
      " [  479  4464   407    93   135]\n",
      " [  827   259  5784   168   227]\n",
      " [  281    73   260  1574    95]\n",
      " [  576   103   290    56  1901]]\n"
     ]
    }
   ],
   "source": [
    "#C= 1\n",
    "print(f'Train accuracy: {model.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7986935623022883\n",
      "Test accuracy: 0.7671000948124069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.76      0.91      0.83     11480\n",
      "          LB       0.90      0.67      0.77      5578\n",
      "          LY       0.74      0.73      0.74      7265\n",
      "          MA       0.76      0.63      0.69      2283\n",
      "          SD       0.68      0.59      0.63      2926\n",
      "\n",
      "    accuracy                           0.77     29532\n",
      "   macro avg       0.77      0.71      0.73     29532\n",
      "weighted avg       0.77      0.77      0.76     29532\n",
      "\n",
      "[[10432    97   518    88   345]\n",
      " [  906  3758   654   100   160]\n",
      " [ 1324   198  5311   214   218]\n",
      " [  389    58   314  1432    90]\n",
      " [  745    67   340    53  1721]]\n"
     ]
    }
   ],
   "source": [
    "#C= 0.1\n",
    "print(f'Train accuracy: {model.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the best model (C=4)\n",
    "import pickle\n",
    "with open('Models/logistic_regression_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "#Saving the vectorizer\n",
    "with open('Models/tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Sample Predictions\n",
    "We test the trained model on some sample text data to predict the dialect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefit\n",
    "This step allows us to qualitatively assess the model's performance and its ability to generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EG'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#writing sample text to find dialect\n",
    "sample_text = ['الموديل بتاعي فيه زوربيح توكينز']\n",
    "sample_text_vectorized = vectorizer.transform(sample_text)\n",
    "model.predict(sample_text_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LY'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#writing sample text to find dialect\n",
    "sample_text = [\" الخميرة قبت والعجينة انكبت \"]\n",
    "sample_text_vectorized = vectorizer.transform(sample_text)\n",
    "model.predict(sample_text_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MA'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#writing sample text to find dialect\n",
    "sample_text = [\"نوضحها تشطح دارتها بصح\"]\n",
    "sample_text_vectorized = vectorizer.transform(sample_text)\n",
    "model.predict(sample_text_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LB'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = ['همي الوحيد صراحه فيق وروح الشغل ويخلص الدوام بسرعه وارجع نام']\n",
    "sample_text_vectorized = vectorizer.transform(sample_text)\n",
    "model.predict(sample_text_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SD'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = ['الافتتاح دا يارب بكون شكل شنو ممكن يكون رساله الي مجهول مثلا']\n",
    "sample_text_vectorized = vectorizer.transform(sample_text)\n",
    "model.predict(sample_text_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train Decision Tree Model\n",
    "We train a Decision Tree model and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree: To compare the performance of a non-linear model with Logistic Regression.\n",
    "## Benefit\n",
    "Decision Trees can capture non-linear relationships and interactions between features, potentially improving classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=50)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9997466551634416\n",
      "Test accuracy: 0.6504808343491806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.72      0.76      0.74     11480\n",
      "          LB       0.70      0.66      0.68      5578\n",
      "          LY       0.61      0.59      0.60      7265\n",
      "          MA       0.61      0.49      0.54      2283\n",
      "          SD       0.43      0.47      0.45      2926\n",
      "\n",
      "    accuracy                           0.65     29532\n",
      "   macro avg       0.61      0.59      0.60     29532\n",
      "weighted avg       0.65      0.65      0.65     29532\n",
      "\n",
      "[[8762  529 1218  213  758]\n",
      " [ 755 3654  747   95  327]\n",
      " [1464  642 4315  332  512]\n",
      " [ 382  159  440 1118  184]\n",
      " [ 860  227  406   72 1361]]\n"
     ]
    }
   ],
   "source": [
    "#Without max_depth\n",
    "print(f'Train accuracy: {model.score(X_train, y_train)}')\n",
    "print(f'Test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5625761746299112\n",
      "Test accuracy: 0.5564133820939997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.74      0.60      0.66     11480\n",
      "          LB       0.83      0.41      0.55      5578\n",
      "          LY       0.37      0.75      0.50      7265\n",
      "          MA       0.79      0.32      0.46      2283\n",
      "          SD       0.60      0.36      0.45      2926\n",
      "\n",
      "    accuracy                           0.56     29532\n",
      "   macro avg       0.67      0.49      0.52     29532\n",
      "weighted avg       0.66      0.56      0.56     29532\n",
      "\n",
      "[[6876   63 4000   36  505]\n",
      " [ 400 2309 2810   24   35]\n",
      " [1330  258 5463  118   96]\n",
      " [ 225   81 1181  734   62]\n",
      " [ 438   79 1345   14 1050]]\n"
     ]
    }
   ],
   "source": [
    "#With max_depth=50\n",
    "print(f'Train accuracy: {model.score(X_train, y_train)}')\n",
    "print(f'Test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train Naive Bayes Model\n",
    "We train a Multinomial Naive Bayes model and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes: To evaluate the performance of a probabilistic model for text classification.\n",
    "## Benefit\n",
    "Naive Bayes is effective for text classification tasks, especially when the features (words) are independent. Comparing its performance with other models helps in selecting the best model for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying naive bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8771893786889062\n",
      "Test accuracy: 0.7791548151158065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.68      0.99      0.80     11480\n",
      "          LB       0.96      0.68      0.79      5578\n",
      "          LY       0.91      0.67      0.77      7265\n",
      "          MA       0.91      0.64      0.76      2283\n",
      "          SD       0.83      0.53      0.65      2926\n",
      "\n",
      "    accuracy                           0.78     29532\n",
      "   macro avg       0.86      0.70      0.75     29532\n",
      "weighted avg       0.82      0.78      0.77     29532\n",
      "\n",
      "[[11335    17    53    22    53]\n",
      " [ 1473  3780   202    29    94]\n",
      " [ 2096    94  4874    73   128]\n",
      " [  641    29   104  1471    38]\n",
      " [ 1241    20   100    15  1550]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Train accuracy: {model.score(X_train, y_train)}')\n",
    "print(f'Test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these steps, we have trained and evaluated multiple models for dialect classification. We compared their performance using various metrics and tested their predictions on sample text data. This comprehensive evaluation helps in selecting the most suitable model for the dialect classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is **Logistic Regression** model with acuraccy  **0.82**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
